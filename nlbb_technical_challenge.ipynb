{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2390410",
   "metadata": {},
   "source": [
    "## nlbb technical challenge\n",
    "\n",
    "Hi I am Bac. Here is my submission for the challenge. \n",
    "\n",
    "After talking with Marius I add:\n",
    "- T-sne for features exploration.\n",
    "- Fix some normalize error.\n",
    "- Offer my opinions about this challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc17903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8e372",
   "metadata": {},
   "source": [
    "### Let check out the data\n",
    "\n",
    "Do some basic sort and covert here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f591cf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-24 11:57:06+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1996170</td>\n",
       "      <td>2144415922528452715</td>\n",
       "      <td>electronics.telephone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>1515915625519388267</td>\n",
       "      <td>LJuJVLEjPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-24 11:57:26+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>139905</td>\n",
       "      <td>2144415926932472027</td>\n",
       "      <td>computers.components.cooler</td>\n",
       "      <td>zalman</td>\n",
       "      <td>17.16</td>\n",
       "      <td>1515915625519380411</td>\n",
       "      <td>tdicluNnRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-24 11:57:27+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>215454</td>\n",
       "      <td>2144415927158964449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1515915625513238515</td>\n",
       "      <td>4TMArHtXQy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-24 11:57:33+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>635807</td>\n",
       "      <td>2144415923107266682</td>\n",
       "      <td>computers.peripherals.printer</td>\n",
       "      <td>pantum</td>\n",
       "      <td>113.81</td>\n",
       "      <td>1515915625519014356</td>\n",
       "      <td>aGFYrNgC08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-24 11:57:36+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>3658723</td>\n",
       "      <td>2144415921169498184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cameronsino</td>\n",
       "      <td>15.87</td>\n",
       "      <td>1515915625510743344</td>\n",
       "      <td>aa4mmk0kwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type  product_id          category_id  \\\n",
       "0 2020-09-24 11:57:06+00:00       view     1996170  2144415922528452715   \n",
       "1 2020-09-24 11:57:26+00:00       view      139905  2144415926932472027   \n",
       "2 2020-09-24 11:57:27+00:00       view      215454  2144415927158964449   \n",
       "3 2020-09-24 11:57:33+00:00       view      635807  2144415923107266682   \n",
       "4 2020-09-24 11:57:36+00:00       view     3658723  2144415921169498184   \n",
       "\n",
       "                   category_code        brand   price              user_id  \\\n",
       "0          electronics.telephone          NaN   31.90  1515915625519388267   \n",
       "1    computers.components.cooler       zalman   17.16  1515915625519380411   \n",
       "2                            NaN          NaN    9.81  1515915625513238515   \n",
       "3  computers.peripherals.printer       pantum  113.81  1515915625519014356   \n",
       "4                            NaN  cameronsino   15.87  1515915625510743344   \n",
       "\n",
       "  user_session  \n",
       "0   LJuJVLEjPT  \n",
       "1   tdicluNnRY  \n",
       "2   4TMArHtXQy  \n",
       "3   aGFYrNgC08  \n",
       "4   aa4mmk0kwQ  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data = pd.read_csv(\"e_commerce_events_history.zip\")\n",
    "# Convert datetime column to datetime type\n",
    "source_data[\"event_time\"] = pd.to_datetime(\n",
    "    source_data[\"event_time\"]\n",
    ")\n",
    "# Sort data by time\n",
    "source_data = source_data.sort_values(\"event_time\")\n",
    "source_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04805b05",
   "metadata": {},
   "source": [
    "### Checking out some data properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e706fea",
   "metadata": {},
   "source": [
    "### Let see how many type of user interaction do we have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723183db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "cart         54035\n",
       "purchase     37346\n",
       "view        793748\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type_count = source_data.groupby(\"event_type\")[\"event_type\"].count()\n",
    "event_type_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3497f69",
   "metadata": {},
   "source": [
    "#### => data have 3 types of interaction only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882376b9",
   "metadata": {},
   "source": [
    "### Let see when user make purchase and how?\n",
    "- We will show some sample of user session where user make the purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b30ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sessions_with_purchases = source_data.groupby(\"user_session\").filter(\n",
    "    lambda x: \"purchase\" in x[\"event_type\"].values\n",
    ")\n",
    "user_sessions_with_purchases = user_sessions_with_purchases.groupby(\"user_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b82319",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ss_key, user_session) in enumerate(user_sessions_with_purchases):\n",
    "    print(user_session[[\"event_time\", \"event_type\", \"product_id\"]], \"\\n\")\n",
    "    if i >=3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f600a",
   "metadata": {},
   "source": [
    "#### => So mostly they have some view then make the purchase directly or adding to cart(no suprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d9205",
   "metadata": {},
   "source": [
    "### Distribution of number of customer interaction in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interaction_count = source_data.groupby(\"user_id\")[\"user_id\"].count()\n",
    "bins = np.arange(0, 15, 1) # fixed bin size\n",
    "num_interact_hist = plt.hist(user_interaction_count, bins=bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fec64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_single_interaction = source_data.groupby(\"user_id\").filter(lambda x: len(x)==1)\n",
    "user_with_single_interaction[\"event_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6efde22",
   "metadata": {},
   "source": [
    "#### => So a big trunk is one time interaction\n",
    "#### => most of them are view, we dont have data to predict in these case let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_multiple_interaction = source_data.groupby(\"user_id\").filter(lambda x: len(x)>1)\n",
    "user_with_multiple_interaction[\"event_time\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57517aad",
   "metadata": {},
   "source": [
    "#### Define a start date for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test_date = datetime.datetime(2021,1,1, tzinfo=datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b41dd7",
   "metadata": {},
   "source": [
    "### Let do some outlier cleaning\n",
    "The only field with real value is price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658599dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_data = user_with_multiple_interaction.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aprice = list(cleaning_data[\"price\"])\n",
    "bins = np.arange(0, 1200, 10) # fixed bin size\n",
    "_ = plt.hist(aprice, bins=bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960c307",
   "metadata": {},
   "source": [
    "Move all outlier above 700USD to 700 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price = 700\n",
    "bins = np.arange(0, 1200, 10) # fixed bin size\n",
    "price_list = cleaning_data[\"price\"]\n",
    "price_clean = [price if price<max_price else max_price for price in price_list]\n",
    "cleaning_data[\"price\"] = price_clean\n",
    "# _ = plt.hist(price_clean, bins=bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa6e27",
   "metadata": {},
   "source": [
    "### Let normalize data\n",
    "We can normalize the whole dataset since we know the max value for price is 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaning_data.copy()\n",
    "clean_data[\"price\"] = [price/max_price for price in clean_data[\"price\"]] \n",
    "bins = np.arange(0, 1, 0.05) # fixed bin size\n",
    "_ = plt.hist(clean_data[\"price\"], bins=bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab48682",
   "metadata": {},
   "source": [
    "### Let go with the most dirty solution\n",
    "#### Let look at detail of last 10 interaction\n",
    "\n",
    "#### Feature 1: Type of last 10 interactions\n",
    "#### Feature 2: Normalize price of last 10 items checked\n",
    "#### Feature 3: User pattern when interact(view the same product/category/brand or not)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72196a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.series import Series\n",
    "def get_last_event_types(interactions: list[Series], depth: int = 10):\n",
    "    \"\"\"Type of interactions user done on the site.\"\"\"\n",
    "    last_events = [0] * depth\n",
    "    event_map = {\n",
    "        \"view\": 1,\n",
    "        \"cart\": 2,\n",
    "        \"purchase\": 3,\n",
    "    }\n",
    "    for i, action in enumerate(interactions):\n",
    "        last_events[i] = event_map[action[\"event_type\"]]\n",
    "    return last_events\n",
    "        \n",
    "def get_last_price(interactions: list[Series], depth: int = 10):\n",
    "    \"\"\"Prices of last items user interact with.\"\"\"\n",
    "    last_prices = [0] * depth\n",
    "    for i, action in enumerate(interactions):\n",
    "        last_prices[i] = action[\"price\"]\n",
    "    return last_prices\n",
    "\n",
    "def get_user_pattern(interactions: list[Series], pattern_name: str, depth: int =10):\n",
    "    \"\"\"Behaviors of user, where the they are checking the same items again or they are checking new one.\"\"\"\n",
    "    last_patterns = [0] * depth\n",
    "    exist_items = []\n",
    "    current_pattern = 0\n",
    "    for i, action in enumerate(interactions):\n",
    "        if action[pattern_name] not in exist_items:\n",
    "            current_pattern +=1\n",
    "            exist_items.append(action[pattern_name])\n",
    "\n",
    "        last_patterns[i] = current_pattern    \n",
    "    return last_patterns\n",
    "\n",
    "def gen_feature_from_list_interaction(interactions: list[Series], depth=10):\n",
    "    if not interactions:\n",
    "        return None\n",
    "    last_interaction = interactions[-depth:]\n",
    "    last_interaction.reverse()\n",
    "    event_types = get_last_event_types(last_interaction)\n",
    "    prices = get_last_price(last_interaction)\n",
    "    products = get_user_pattern(last_interaction, pattern_name=\"product_id\")\n",
    "    categories = get_user_pattern(last_interaction, pattern_name=\"category_code\")\n",
    "#     brands = get_user_pattern(last_interaction, pattern_name=\"brand\")\n",
    "#     sessions = get_user_pattern(last_interaction, pattern_name=\"user_session\")\n",
    "\n",
    "    return event_types + prices + products + categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = []\n",
    "label_data = []\n",
    "event_time = []\n",
    "user_ids = []\n",
    "event_map = {\n",
    "    \"view\": 0,\n",
    "    \"cart\": 1,\n",
    "    \"purchase\": 2, \n",
    "}\n",
    "\n",
    "\n",
    "for i, (user_id, user_interact_df) in enumerate(clean_data.groupby(\"user_id\")):\n",
    "    prev_interaction = []\n",
    "    for index, row in user_interact_df.iterrows():\n",
    "        label = event_map[row[\"event_type\"]]\n",
    "        feature = gen_feature_from_list_interaction(prev_interaction)\n",
    "        prev_interaction.append(row)\n",
    "        if feature is None:\n",
    "            continue\n",
    "        feature_data.append(np.array(feature))\n",
    "        label_data.append(label)\n",
    "        event_time.append(row[\"event_time\"])\n",
    "        user_ids.append(row[\"user_id\"])\n",
    "#     if i > 10000:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_model = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"features\": feature_data,\n",
    "        \"labels\": label_data,\n",
    "        \"event_time\": event_time,\n",
    "        \"user_ids\": user_ids,\n",
    "    }\n",
    ")\n",
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8af4e",
   "metadata": {},
   "source": [
    "### Visualize some data to check features quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd73bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scatter(x, colors):\n",
    "    # choose a color palette with seaborn.\n",
    "    num_classes = len(np.unique(colors))\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        # Position of each label at median of data points.\n",
    "\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_tsne_features(X, y):\n",
    "    time_start = time.time()\n",
    "    feat_tsne = TSNE(random_state=0).fit_transform(X)\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    feature_scatter(feat_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768805e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "vis_sample_num = 10000\n",
    "x_subset = np.array(list(data_for_model[\"features\"]))[:vis_sample_num]\n",
    "y_tsne = np.array(list(data_for_model[\"labels\"]))[:vis_sample_num]\n",
    "vis_tsne_features(x_subset, y_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513570",
   "metadata": {},
   "source": [
    "#### RED = View, BLUE = Cart, GREEN = Purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44d919",
   "metadata": {},
   "source": [
    "#### Some analysis\n",
    "#### The first thing is I dont think predict the \"next action\" is a good ideas because:\n",
    "\n",
    "1. The next action is too abitrary, from the t-sne vis we can see that there are no distinstion between type of actions.(A reason is our features is not good enough but I dont think we can change much by update features).\n",
    "2. There are not much business value in predict the next immediate action. In my opinion, somethink like:\n",
    "- Predict whether user will continue have more interactions on the site.\n",
    "- Predict purchase/cart action in next 10 interactions.\n",
    "\n",
    "=> These kind of signal will have more business sense and we can predict with more accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6240341",
   "metadata": {},
   "source": [
    "### But let train a model anyway\n",
    "### Split train - test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_for_model[data_for_model[\"event_time\"] < start_test_date]\n",
    "test_data = data_for_model[data_for_model[\"event_time\"] >= start_test_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d7681",
   "metadata": {},
   "source": [
    "### Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = np.array(list(train_data[\"features\"]))\n",
    "y_train = np.array(list(train_data[\"labels\"]))\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver=\"saga\", max_iter=1e8).fit(X_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1841f5",
   "metadata": {},
   "source": [
    "### Filter the the first user interaction for each users in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b83540",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = test_data.groupby(\"user_ids\")\n",
    "X_test = []\n",
    "y_test = []\n",
    "for user_id, interactions in user_groups:\n",
    "    first_interaction = interactions.iloc[0]\n",
    "    X_test.append(first_interaction[\"features\"])\n",
    "    y_test.append(first_interaction[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c566c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler_test.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_pred\n",
    "from collections import Counter\n",
    "Counter(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f159cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef89454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['view', 'cart', 'purchase']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc1fb6",
   "metadata": {},
   "source": [
    "### As expect the result is terrible. And we should re-consider this aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748edc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fb098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
